# 安装yarn集群
 1、在node1进入hadoop的安装目录下的/usr/local/hadoop-2.7.5/etc/hadoop(供参考)目录下,将mapred-site.xml.template文件通过 mv mapred-site.xml.template mapred-site.xml 命令修改为mapred-site.xml文件:
        <property>
                  <name>mapreduce.framework.name</name>
                  <value>yarn</value>
         </property>
        2、在node1同目录下配置yarn-site.xml文件
              <property>
                 <name>yarn.nodemanager.aux-services</name>
                 <value>mapreduce_shuffle</value>
         </property>
        <property>
                 <name>yarn.resourcemanager.ha.enabled</name>
                 <value>true</value>
         </property>
         <property>
                 <name>yarn.resourcemanager.cluster-id</name>
                 <value>cluster1</value>
         </property>
         <property>
                 <name>yarn.resourcemanager.ha.rm-ids</name>
                 <value>rm1,rm2</value>
        </property>
         <property>
                 <name>yarn.resourcemanager.hostname.rm1</name>
                 <value>node1</value>
         </property>
         <property>
                 <name>yarn.resourcemanager.hostname.rm2</name>
                 <value>node2</value>
         </property>
         <property>
                 <name>yarn.resourcemanager.zk-address</name>
                 <value>node2:2181,node3:2181</value>
        </property>
        3、在node2、node3分别配置这两个配置文件。
        4、在node1上启动yarn。
        5、在另外一个节点上单独启动(node2)。
        命令:yarn-daemon.sh start
        6、在node1启动hdfs
        命令:start-dfs.sh
        7、对搭建的yarn集群进行测试
        8、集群搭建测试成功,也可以通过node01:8088在网页中查看

# 安装kafka
1）解压安装包
tar -zxvf kafka_2.11-0.11.0.2.tgz -C /usr/local/
2）修改解压后的文件名称
mv kafka_2.11-0.11.0.2 kafka_2.11-0.11
3）在/usr/local/kafka_2.11.0.11目录下创建logs文件夹
mkdir logs
4）修改配置文件
cd config/
vim server.properties
输入以下内容：
#broker的全局唯一编号，不能重复
broker.id=0
#删除topic功能使能
delete.topic.enable=true
#kafka运行日志（还有生产者发给kafka的消息）存放的路径
log.dirs=usr/local/kafka _2.11-0.11/logs
#配置连接Zookeeper集群地址
zookeeper.connect=node1:2181,node2:2181,node3:2181
5）配置环境变量
sudo vi /etc/profile
#KAFKA_HOME
export KAFKA_HOME=/usr/local/kafka _2.11-0.11
export PATH=$PATH:$KAFKA_HOME/bin
source /etc/profile
6）分发安装包
scp -r  kafka _2.11-0.11 node2 $:PWD
scp -r  kafka _2.11-0.11 node3 $:PWD
	注意：分发之后记得配置其他机器的环境变量
7）分别在node2和node3上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2
	注：broker.id不得重复
# 安装redis集群
创建集群(最少有3个节点，6台服务器，每个节点有一个备份机)：
        1.创建集群文件夹：
            命令：
                cd /usr/local
                mkdir redis-cluster
        2.复制redis(-r表示全部文件)为redis01到创建的集群中
            命令：
                cp redis redis-cluster/redis01 -r
        3.修改配置文件
            命令：
                cd /usr/local/redis-cluster
                cd redis01
                vi redis.conf
                    找到port 6379  改为port XXXX
                    找到cluster-enabled yes将前面的注释去掉(表示开启集群)
        4.复制redis01  复制5份，修改port xxxx
            命令：
                cd /usr/local/redis-cluster
                cp redis redis02 -r
                cp redis redis03 -r
        5.设置开启脚本
            命令：
                cd /usr/local/redis-cluster
                vi startall.sh
                内容 cd redis01
                     ./bin/redis-server redis.conf
                     cd ..
                     cd redis02
                     ./bin/redis-server redis.conf
                     cd ..等
                保存退出wq
        6.设置权限
            命令：
                cd /usr/local/redis-cluster
                chmod u+x startall.sh
        7.开启集群实例
            命令：
                cd /usr/local/redis-cluster
                ./startall.sh
        8.查看是否开启
            命令：
                ps -ef | grep redis
        9.编写停止脚本
            命令：
                cd /usr/local/redis-cluster
                 vi stopall.sh
                内容 cd redis01
                     ./bin/redis-cli -p 7001 shutdown
                     cd ..
                     cd redis02
                     ./bin/redis-cli -p 7002 shutdown
                     cd ..等
                保存退出wq
        10.设置权限
            命令：
                cd /usr/local/redis-cluster
                chmod u+x stopall.sh
        11.执行
            命令：
                cd /usr/local/redis-cluster
                ./stopall.sh
        12.搭建集群环境
            命令：
                yum install ruby
                yum install rubygems
                上传包（rz）redis-3.0.0.gem
                安装(gem install redis-3.0.0.gem)
        13.进入 redis3.0.7/src下  执行表示开启集群
            命令：
                cd /usr/soft/redis-3.0.7/src
                ll *.rb
                ./redis-trib.rb
        14.把集群实例开启，搭建集群
            命令：
                cd /usr/local/redis-cluster
                ./startall.sh
                cd /usr/soft/redis-3.0.7/src
            ./redis-trib.rb create --replicas 1 192.168.56.170:7001 192.168.56.171:7002 192.168.56.172:7003 192.168.56.173:7004 192.168.56.174:7005 192.168.56.175:7006
        15.连接集中的客户端：进入随便一个节点连接
            命令：
                cd /usr/local/redis-cluster/redis01
                ./bin/redis-cli -p 7001 -c  （ -c 连接集群，可以自动跳槽）
# 安装spark集群
1 安装spark包
1.1 将spark-2.0.2-bin-hadoop2.7.tgz主机Mac的终端分别传输到node1中的/usr/local目录下
1.2 使用命令进行解压缩spark-2.0.2-bin-hadoop2.7.tgz，
命令为：tar -zvxf spark-2.0.2-bin-hadoop2.7.tgz
1.3 重命名：mv spark-2.0.2-bin-hadoop2.7 spark
1.4 配置spark相关的环境变量
vi ~/.bashrc
export SPARK_HOME=/usr/local/spark
export PATH=$SPARK_HOME/bin
export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib
source ~/.bashrc
2 修改spark-env.sh文件
2.1 键入命令：cd /usr/local/spark/conf
2.2 键入命令：mv spark-env.sh.template spark-env.sh
2.3 修改spark-env.sh，命令：vi spark-env.sh
###jdk安装目录
export JAVA_HOME=/usr/java/latest
###scala安装目录
export SCALA_HOME=/usr/local/scala
###spark集群的master节点的ip，node1
export SPARK_MASTER_IP=192.168.56.101
###指定worker节点能够最大分配给Excutors的内存大小
export SPARK_WORKER_MEMORY=1g
###hadoop集群的配置文件目录
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
3 配置slaves文件
3.1 修改/usr/local/spark/conf/slaves.template的名字，命令：mv slaves.template slaves
3.2 键入命令：vi slaves
node2
node3
4  将node1中的spark、~/.bashrc通过scp命令拷贝node2、node3中，命令：
scp -r spark root@node2:/usr/local
scp -r spark root@node3:/usr/local
scp ~/.bashrc root@node2:~
scp ~/.bashrc root@node3:~
然后，在node2和node3中，分别执行命令：source ~/.bashrc，使得配置文件生效
5 启动Spark集群
5.1 首先进入/usr/local/spark/sbin目录下
5.2 执行./start-all.sh
5.3 使用jps，8080端口，spark-shell进行检查集群是否启动成功
主机上浏览器8080端口检查结果

Spark-shell

# 安装hdfs集群
1、修改linux主机名
hostnamectl set-hostname "node1"
hostnamectl set-hostname "node1" --static
hostnamectl set-hostname "node1" --transient
hostnamectl set-hostname "node1" --pretty

修改网络映射
vi /etc/hosts
192.168.56.101 node1

查看防火墙状态
firewall-cmd --state
关闭防火墙
systemctl stop firewalld.service
永久禁用防火墙
systemctl disable firewalld.service

查看selinux
/usr/sbin/sestatus -v
关闭selinux
vi /etc/selinux/config
SELINUX=disabled
然后重启

安装jdk
tar -zxvf jdk.tgz -C /usr/local
vi /etc/profile
JAVA_HOME=/usr/local/jdk1.8.0_192
PATH=$JAVA_HOME/bin:$PATH
export JAVA_HOME PATH

安装完全分布式hdfs
tar -zxvf hadoop.2.8.5.tar.gz -C /usr/local
cd hadoop/etc/hadoop
vi core-site.xml
<configuration>
<property>
<name>fs.defaultFS</name>
<value>hdfs://node1/</value>
</property>
</configuration>

vi hdfs-site.xml
<configuration>
<property>
<name>dfs.namenode.name.dir</name>
<value>/usr/local/hdpdata/name</value>
</property>

<property>
<name>dfs.datanode.data.dir</name>
<value>/usr/local/hdpdata/data</value>
</property>
<property>
  <name>dfs.namenode.secondary.http-address</name>
  <value>node2:50090</value>
</property>
<property>
  <name>dfs.namenode.checkpoint.dir</name>
  <value>/usr/local/hdpdata/namesecondary</value>
</property>
</configuration>
vi slaves
node1
node2
node3
//分发到所有节点
vi /etc/profile
HADOOP_HOME=
PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
export ...
source /etc/profile
//免密登录
ssh-genkey -t rsa  //生成密钥
ssh-copy-id 要进行免密登录的ip  //namenode需要对所有的节点进行免密

启动命令
start-dfs.sh
停止
stop-dfs.sh

#  springboot部署（配置文件怎么配）
 springboot介绍
 大家知道springboot是基于spring研发出来的，但是要知道springboot其实并不是对spring功能的增强，而是提供了一种快速使用spring的方式或者说是工具。
 springboot集合了大量的第三方库，Spring Boot应用中这些第三方库几乎可以是零配置的开箱即用，大部分的 Spring Boot 应用都只需要非常少量的配置代码（基于 Java 的配置），开发者能够更加专注于业务逻辑。
 - 优点
 – 1.springboot本身就是基于spring诞生的，可以说只要spring能实现的功能，springboot都能实现，功能强大。
 – 2.方便构建项目，我们都知道以前在使用spring框架构建项目的时候，免不了很多的配置文件，各种装配bean，现在springboot几乎实现了0配置文件，它采用了java config的方式，对spring进行配置，采用注解配置的方式，简化了原先的繁多的配置文件，极高的提高了工作效率。通过@Configuration 和@Bean 两个注解完成配置文件。

 – 3.简化了maven配置，虽然spring4.0的出现似乎也已经做到了无xml配置，但是却需要繁多的maven配置，甚至达到了数百行，如今springboot集合了大量的第三方库，将大量的依赖配置集成简单的maven配置，

 springboot项目在创建的时候就会自带一些maven配置，这些配置就已经集成了大量的依赖，不在需要开发者耗时耗力的去添加依赖配置了。
 – 4 简化部署
 springboot内部嵌入了tomcat，在spring-boot-starter-web里可以找到，

 这样在研发过程中就不在需要tomcat服务器，并且springboot项目在打完jar之后，可以直接启动也不需要另外的本地tomcat。也就是说拿到springboot项目jar之后，完全可以在一台只有jdk的机器上启动了。

 springboot启动
 上面说过了springboot项目自带了tomcat，所以项目启动和部署不需要额外的tomcat服务器了，这里关键的是springboot项目会有一个启动类，这个是springboot项目的入口
 上面可以看出启动类需要一个关键的注解@SpringBootApplication，看下改注解背后的内容，
 @Target(ElementType.TYPE)            // 注解的适用范围，其中TYPE用于描述类、接口（包括包注解类型）或enum声明
 @Retention(RetentionPolicy.RUNTIME)  // 注解的生命周期，保留到class文件中（三个生命周期）
 @Documented                          // 表明这个注解应该被javadoc记录
 @Inherited                           // 子类可以继承该注解
 @SpringBootConfiguration             // 继承了Configuration，表示当前是注解类
 @EnableAutoConfiguration             // 开启springboot的注解功能，springboot的四大神器之一，其借助@import的帮助
 @ComponentScan(excludeFilters = {    // 扫描路径设置（具体使用待确认）
         @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
         @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })
 public @interface SpringBootApplication {
 ...
 }
 可以看出@SpringBootApplication使用了多个注解，其中最为重要的就是
 @Configuration 使用javaconfig方式进行配置，形式的Spring Ioc容器的配置类
 @EnableAutoConfiguration 比较重要的，这里不做解释了
 @ComponentScan 扫描注解，自动扫描并加载符合条件的组件
 其实可以说，你可以使用@SpringBootApplication，你也可以使用以上三个注解都一样。
 有个这些，你就可以简单的理解，启动一个springboot项目，会从启动类入口进去，通过@SpringBootApplication注解之后自动的去扫描加载一些javaconfig 配置，启动内置tomcat将项目运行起来。
 springboot项目部署
 我们以前在部署web项目的时候基本山都是打成war包放到tomcat的webapp下面，启动tomcat。这种方式不仅仅耗时耗力，还需要要求部署项目的服务器事先就要有能够部署的环境。有时候还需要手动修改tomcat配置文件。
 springboot就是极大的简化了项目的部署。
 我们只需要将项目打成jar包，然后放在只需要有jdk的服务器上，java -jar ***就能启动项目了。
 那么问题来了，以往我们对于web项目都是war包的形式进行部署的，为啥springboot项目却能想启动java应用程序一样部署呢？
 上面也已经说过了，springboot是内置tomcat了的，所以项目启动的时候回自动启动tomcat，但是我们都知道启动jar文件都是需要有主类（main），
 没错，它是就是我们的启动类，既然是主类，那肯定就会有启动弄类配置的吧，就是这个maven-shade-plugin，去找找看。


 springboot通过maven插件配置了启动类，所以就可以java -jar的形式启动项目，启动类被启动之后就会扫描加载配置，启动内置的tomcat等，最后完成了项目的启动部署了。








